data(mtcars)
Variabili:
  VS vale 0(conf V) 1(in linea)
  mpg
  am (cambio automatico o no)

dati <- mtcars[, c('mpg', 'vs', 'am')]
chiedere se am e' qualitativa  ->  FALSE, significa che la interpreta come numerica,
dunque va riqualificata come variabile qualitativa cosi':  dati$am <- as.factor(dati$am)


boxplot(dati$mpg ~ dati$vs)   ->    mpg sembra influenzare molto, perche' le scatole sono separate
boxplot(dati$mpg ~ dati$vs * dati$am)  ->   4 boxplot perche' sono le 4 combinazioni di vs e am
   	==> il primo e il terzo boxplot sono per vs = 0, il secondo e il quarto sono per vs = 1
	===> sembra che am influenzi le variazioni di vs



Costruiamo il modello lineare, generalizzato logistico (comando 'glm'):
modello <- glm(vs ~ mpg*am, data = dati, family = binomial) ==> 
Call:
glm(formula = vs ~ mpg * am, family = binomial, data = dati)

Deviance Residuals: 
     Min        1Q    Median        3Q       Max  
-1.70566  -0.31124  -0.04817   0.28038   1.55603  

Coefficients:			###no p value ma z value
            Estimate Std. Error z value Pr(>|z|)  
(Intercept) -20.4784    10.5525  -1.941   0.0523 .
mpg           1.1084     0.5770   1.921   0.0547 .
am1          10.1055    11.9104   0.848   0.3962  
mpg:am1      -0.6637     0.6242  -1.063   0.2877  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1) ==> significa che quando
ci sono i modelli lineari generalizzati, i dati possono essere troppo variabili rispetto a quello
che prevede il modello, dunque si puo' impostare un parametro di dispersione

Null deviance: 43.860  on 31  degrees of freedom     ===>  segue Chi^2, piu' la devianza
 e' piccola, piu' il modello e' corretto, si rifiuta il modello corrente per valori grandi della 
 devianza; un Chi^2 con 31 gradi di liberta' ha media 31, 43 va oltre 31, quindi il modello non va bene
 NB: qchisq(0.95, 31)  =  44.98534    =====>     siamo sulla soglia del rifiuto
	NB: non e' strano perche' solo mpg e' appena significativo, visto il '.'
Residual deviance: 19.125  on 28  degrees of freedom   = 
  1 - pchisq(19.125, 28) = 0.8942349 (valore alto)   ---> indica che e' meglio avere meno variabili

AIC: 27.125

Number of Fisher Scoring iterations: 7



NUOVO MODELLO


modello2 <- update(modello, . ~ . - mpg:am)      ->    tolta l'interazione mpg:am
Call:
glm(formula = vs ~ mpg + am, family = binomial, data = dati)

Deviance Residuals: 
     Min        1Q    Median        3Q       Max  
-2.05888  -0.44544  -0.08765   0.33335   1.68405  

NB: vale la solita interpretazione dei coefficienti
Coefficients:
            Estimate Std. Error z value Pr(>|z|)   
(Intercept) -12.7051     4.6252  -2.747  0.00602 **     
mpg           0.6809     0.2524   2.698  0.00697 **       
am1          -3.0073     1.5995  -1.880  0.06009 . 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

NB: Non ci sono piu' R^2 etc... solo devianze
Null deviance: 43.860  on 31  degrees of freedom
Residual deviance: 20.646  on 29  degrees of freedom
AIC: 26.646

Confrontiamo i modelli:
anova(modello2, modello, test = 'Chisq')   ===> OUTPUT
 Analysis of Deviance Table
 Model 1: vs ~ mpg + am		(modello piu' piccolo)	
 Model 2: vs ~ mpg * am		(piu' grande)
  Resid. Df Resid. Dev Df Deviance Pr(>Chi)
 1        29     20.646                     
 2        28     19.125  1   1.5214   0.2174
 La devianza del modello piu' piccolo e' piu' grande della devianza del modello piu' grande
 1 - pchisq(1.5214,1)
 [1] 0.2174078

Number of Fisher Scoring iterations: 6

INTERVALLO di confidenza: come nel modello lineare: 
   0.680 - qnorm(0.95) * 0.2524
   0.680 + qnorm(0.95) * 0.2524


TOGLIAMO am: modello3 <- update(modello2, . ~ . - am)
  -> ora e' tutto significativo

anova(modello3, modello2, test= 'Chisq')
par(mfrow=c(2,2))

plot(modello2)

COME SI STIMANO I VALORI DEL MODELLO:
diverso dal modello lineare(y cappello), qui si stima 'logit P (vs)' o 'P(vs)' cappello
 valori.stimati <- predict(m odello2)   ==> di default da' il logit
 Per P(vs) : valori.stimati <- predict(modello2, type = 'response')

plot(dati$mpg, dati$vs)   -->   dati disposti su 2 linee perche' sono di tipo 0/1
curve(predict(modello2, newdata=data.frame(mpg=x, am = '0'), type='response'), add=TRUE)
  :   il comando curve ha bisogno solo dell'esp> prob.stimate <- predict(modello2, type = 'response')
> previsioni [prob.stimate > 0.5] <- regressione per costruire la curva, 
      costruisci le previsioni del modello 2 sulla scala delle probabilita', con ascissa mpg
curve(predict(modello2, newdata=data.frame(mpg=x, am = '1'), type='response'), add=TRUE,    lty=2, lwd=2)
## vs = 1, valori con prob.stimate > 0.5

> prob.stimate <- predict(modello2, type = 'response')
> previsioni [prob.stimate > 0.5] <- 1
> table(previsioni, dati$vs)
          
previsioni  0  1
         0 15  4
         1  3 10

n <- nrow(dati)

> set.seed(222)
> selezione <- sample(n, 0.60*n)
> selezione <- sample(n, 0.60*n, replace = FALSE)
> training.set <- dati[selezione, ]
> test.set <- dati(-selezione,)
> test.set <- dati[-selezione,]


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$


ANALISI DISCRIMINANTE LINEARE
modello.lda <- lda(vs ~ mpg + am, data=training.s
funzione discriminante: 0.326 * mpg - 1.9399 * am1
plot(modello.lda)  ===> da' l'istogramma delle classificazione
> previsioni.lda <- predict(modello.=lda, test.set)
table(previsioni.lda$class, test.set$vs)
> valori.roc <- roc(test.set$vs, previsioni.lda$posterior[,2])
